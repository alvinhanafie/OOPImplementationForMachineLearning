{"cells":[{"cell_type":"markdown","id":"ccd7e841","metadata":{},"source":["# OOP Implementation for Classification and Regression Metrics Evaluation"]},{"cell_type":"code","execution_count":689,"id":"c9610fc9","metadata":{},"outputs":[],"source":["# import library from scikit-learn for crosscheck in the final step\n","\n","from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"]},{"cell_type":"code","execution_count":690,"id":"6cb1e384","metadata":{},"outputs":[],"source":["# super / parent class for both classification and regression metrics evaluation \n","\n","class BaseEvaluation():\n","    def __init__(self):        \n","        self._actual_values = []\n","        self._predicted_values = []\n","\n","    # get_values to get the current actual and predicted values for metrics evaluation\n","    def get_values(self):\n","        print('Actual Values:', self._actual_values)\n","        print('Predicted Values:', self._predicted_values)\n","        \n","    # set_values to add actual and predicted values for metrics evaluation\n","    def set_values(self, actual_values, predicted_values): \n","        if not isinstance(actual_values, list) or not isinstance(predicted_values, list):\n","            raise ValueError(\"Please input data with the type of list.\")\n","\n","        if len(actual_values) != len(predicted_values):\n","            raise ValueError('Dataset for actual and predicted values are not in the same length')\n","        \n","        self._actual_values.extend(actual_values)\n","        self._predicted_values.extend(predicted_values)\n","\n","    # _check_values to check whether any data already inputted for metrics evaluation\n","    def _check_values(self):\n","        if not self._actual_values or not self._predicted_values:\n","            raise ValueError(\"No data for metrics evaluation. Please add some values by using the set_values function.\")\n","        \n","    # reset to restart the process of metrics evaluation\n","    def reset(self):\n","        self._actual_values = []\n","        self._predicted_values = []"]},{"cell_type":"code","execution_count":691,"id":"71c44be5","metadata":{},"outputs":[],"source":["# sub / child class for classification metrics evaluation\n","\n","class ClassificationEvaluation(BaseEvaluation):\n","    def accuracy(self):\n","        self._check_values()\n","        \n","        # true prediction to calculate the total of true positive and true negative)\n","        true_prediction = [1 for y_true, y_pred in zip(self._actual_values, self._predicted_values) if y_true == y_pred]\n","        total_dataset = len(self._actual_values)\n","\n","        return sum(true_prediction)/total_dataset\n","    \n","    def precision(self):\n","        self._check_values()\n","\n","        # true positive to calculate the total of true positive)\n","        true_positive = [1 for y_true, y_pred in zip(self._actual_values, self._predicted_values) if (y_true + y_pred == 2)]\n","        # predicted positive to calculate the total of false positive)\n","        predicted_positive = [1 for y_true, y_pred in zip(self._actual_values, self._predicted_values) if ((y_true == 0) and (y_pred == 1))]\n","\n","        return sum(true_positive)/(sum(true_positive) + sum(predicted_positive))\n","\n","    def recall(self):\n","        self._check_values()\n","       \n","        true_positive = [1 for y_true, y_pred in zip(self._actual_values, self._predicted_values) if (y_true + y_pred == 2)]\n","        # predicted negative to calculate the total of false negative)\n","        predicted_negative = [1 for y_true, y_pred in zip(self._actual_values, self._predicted_values) if ((y_true == 1) and (y_pred == 0))]\n","\n","        return sum(true_positive)/(sum(true_positive) + sum(predicted_negative))\n","    \n","    def f1(self):\n","        self._check_values()\n","\n","        precision = self.precision()\n","        recall = self.recall()\n","\n","        return (2*precision*recall/(precision+recall))\n","    \n","    # evaluate function to evaluate all evaluation metrics\n","    def evaluate(self):\n","        return {\n","            \"Accuracy\": self.accuracy(),\n","            \"Precision\": self.precision(),\n","            \"Recall\": self.recall(),\n","            \"F1 Score\": self.f1()\n","            }\n"]},{"cell_type":"code","execution_count":692,"id":"c4011d8a","metadata":{},"outputs":[],"source":["# data dummy for classification metrics evaluation\n","\n","classification_actual_label = [1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1]\n","classification_predicted_labels = [1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1]"]},{"cell_type":"code","execution_count":693,"id":"05d282a6","metadata":{},"outputs":[],"source":["# create object from class ClassificationEvaluation()\n","\n","classification_evaluation = ClassificationEvaluation()"]},{"cell_type":"code","execution_count":694,"id":"857768d9","metadata":{},"outputs":[],"source":["# data input for metrics evaluation\n","\n","classification_evaluation.set_values(classification_actual_label, classification_predicted_labels)"]},{"cell_type":"code","execution_count":695,"id":"c3c52c5e","metadata":{},"outputs":[{"data":{"text/plain":["{'Accuracy': 0.8, 'Precision': 0.8125, 'Recall': 0.8125, 'F1 Score': 0.8125}"]},"execution_count":695,"metadata":{},"output_type":"execute_result"}],"source":["# classification metrics evaluation\n","\n","classification_evaluation.evaluate()"]},{"cell_type":"code","execution_count":696,"id":"4f25e25e","metadata":{"id":"4f25e25e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8, Precision: 0.8125, Recall: 0.8125, F1 Score: 0.8125\n"]}],"source":["# cross check with scikit-learn methods for metrics evaluation\n","\n","accuracy_scikit = accuracy_score(classification_actual_label, classification_predicted_labels)\n","precision_scikit = precision_score(classification_actual_label, classification_predicted_labels)\n","recall_scikit = recall_score(classification_actual_label, classification_predicted_labels)\n","f1_scikit = f1_score(classification_actual_label, classification_predicted_labels)\n","\n","print(f'Accuracy: {accuracy_scikit}, Precision: {precision_scikit}, Recall: {recall_scikit}, F1 Score: {f1_scikit}')"]},{"cell_type":"markdown","id":"589e1fe1","metadata":{},"source":["Summary: Evaluation metrics for classification from ClassificationEvaluation() class and scikit-learn method show the same values. "]},{"cell_type":"code","execution_count":697,"id":"7ed74993","metadata":{"id":"7ed74993"},"outputs":[],"source":["# sub / child class for regression metrics evaluation\n","\n","\n","class RegressionEvaluator(BaseEvaluation):\n","\n","    def mean_absolute_error(self):\n","        self._check_values()\n","\n","        # calculate absolute errors\n","        errors = [abs(y_true - y_pred) for y_true, y_pred in zip(self._actual_values, self._predicted_values)]\n","        return sum(errors) / len(errors)\n","    \n","    def mean_squared_error(self):\n","        self._check_values()\n","\n","        # calculate squared errors\n","        errors = [(y_true - y_pred)**2 for y_true, y_pred in zip(self._actual_values, self._predicted_values)]\n","        return sum(errors) / len(errors)\n","    \n","    def r2_score(self):\n","        self._check_values()\n","\n","        # calculate explained variation and total variation\n","        explained_variation = [(y_true - y_pred)**2 for y_true, y_pred in zip(self._actual_values, self._predicted_values)]\n","        average_y_true = sum(self._actual_values)/len(self._actual_values)\n","        total_variation = [(y_true - average_y_true)**2 for y_true in self._actual_values]\n","        return 1 - sum(explained_variation) / sum(total_variation)\n","\n","    # evaluate function to evaluate all evaluation metrics\n","    def evaluate(self):\n","        return {\n","            'MAE': self.mean_absolute_error(),\n","            'MSE': self.mean_squared_error(),\n","            'R2': self.r2_score(),\n","        }\n","\n"]},{"cell_type":"code","execution_count":698,"id":"93d90238","metadata":{},"outputs":[],"source":["# data dummy for regression metrics evaluation\n","\n","\n","regression_actual_values = [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155]\n","regression_predicted_values = [12, 18, 22, 28, 29, 38, 42, 48, 51, 58, 62, 68, 73, 78, 82, 88, 92, 96, 102, 110, 112, 118, 122, 128, 133, 138, 142, 148, 152, 158]"]},{"cell_type":"code","execution_count":699,"id":"0c310cb3","metadata":{"id":"0c310cb3"},"outputs":[],"source":["# create object from class RegressionEvaluation()\n","\n","regression_evaluation = RegressionEvaluator()\n"]},{"cell_type":"code","execution_count":700,"id":"da1093e0","metadata":{},"outputs":[],"source":["# data input for metrics evaluation\n","\n","regression_evaluation.set_values(regression_actual_values, regression_predicted_values)"]},{"cell_type":"code","execution_count":701,"id":"e1aeb940","metadata":{},"outputs":[{"data":{"text/plain":["{'MAE': 2.5, 'MSE': 6.9, 'R2': 0.9963159065628476}"]},"execution_count":701,"metadata":{},"output_type":"execute_result"}],"source":["# regression metrics evaluation\n","\n","regression_evaluation.evaluate()"]},{"cell_type":"code","execution_count":702,"id":"c6469e2b","metadata":{"id":"c6469e2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 2.5, MSE: 6.9, R2: 0.9963159065628476\n"]}],"source":["# cross check with scikit-learn methods for metrics evaluation\n","\n","mae_scikit = mean_absolute_error(regression_actual_values, regression_predicted_values)\n","mse_scikit = mean_squared_error(regression_actual_values, regression_predicted_values)\n","r2_scikit = r2_score(regression_actual_values, regression_predicted_values)\n","\n","print('MAE: {}, MSE: {}, R2: {}'.format(mae_scikit, mse_scikit, r2_scikit))\n"]},{"cell_type":"markdown","id":"31b59370","metadata":{},"source":["Summary: Evaluation metrics for regression from RegressionEvaluation() class and scikit-learn method show the same values. "]},{"cell_type":"markdown","id":"ed96c99d","metadata":{},"source":["## Additional (Checking other functions)"]},{"cell_type":"code","execution_count":703,"id":"9d8881e7","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Actual Values: [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155]\n","Predicted Values: [12, 18, 22, 28, 29, 38, 42, 48, 51, 58, 62, 68, 73, 78, 82, 88, 92, 96, 102, 110, 112, 118, 122, 128, 133, 138, 142, 148, 152, 158]\n"]}],"source":["# check current values inside regression_evaluation\n","\n","regression_evaluation.get_values()"]},{"cell_type":"code","execution_count":704,"id":"bbe31a73","metadata":{},"outputs":[],"source":["# add more values to regression_evaluation\n","\n","regression_evaluation.set_values([103], [107])"]},{"cell_type":"code","execution_count":705,"id":"8b93f4b4","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Actual Values: [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 103]\n","Predicted Values: [12, 18, 22, 28, 29, 38, 42, 48, 51, 58, 62, 68, 73, 78, 82, 88, 92, 96, 102, 110, 112, 118, 122, 128, 133, 138, 142, 148, 152, 158, 107]\n"]}],"source":["# check current values inside regression_evaluation after data addition\n","\n","regression_evaluation.get_values()"]},{"cell_type":"code","execution_count":706,"id":"14b3036c","metadata":{},"outputs":[{"data":{"text/plain":["{'MAE': 2.5483870967741935, 'MSE': 7.193548387096774, 'R2': 0.996059666442471}"]},"execution_count":706,"metadata":{},"output_type":"execute_result"}],"source":["# evaluate using additional data\n","\n","regression_evaluation.evaluate()"]},{"cell_type":"code","execution_count":707,"id":"396fb8fb","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 2.5483870967741935, MSE: 7.193548387096774, R2: 0.996059666442471\n"]}],"source":["# cross check with scikit learn method\n","\n","mae_scikit = mean_absolute_error(regression_evaluation._actual_values, regression_evaluation._predicted_values)\n","mse_scikit = mean_squared_error(regression_evaluation._actual_values, regression_evaluation._predicted_values)\n","r2_scikit = r2_score(regression_evaluation._actual_values, regression_evaluation._predicted_values)\n","\n","print(f'MAE: {mae_scikit}, MSE: {mse_scikit}, R2: {r2_scikit}')"]},{"cell_type":"code","execution_count":708,"id":"6eab2b4c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Actual Values: []\n","Predicted Values: []\n"]}],"source":["# check reset function\n","\n","regression_evaluation.reset()\n","regression_evaluation.get_values()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}
